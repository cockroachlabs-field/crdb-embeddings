 Page}}     In computer operating systems, "memory paging" (or "swapping" on some Unix-like systems) is a memory management scheme by which a computer stores and retrieves data from Computer data storage#Secondary storage|secondary storage for use in Computer data storage#Primary storage|main memory. In this scheme, the operating system retrieves data from secondary storage in same-size Block (data storage)|blocks called "Page (computer memory)|pages". Paging is an important part of virtual memory implementations in modern operating systems, using secondary storage to let programs exceed the size of available physical memory. For simplicity, main memory is called "RAM" (an acronym of random-access memory) and secondary storage is called "disk" (a shorthand for hard disk drive, drum memory or solid-state drive, etc.), but as with many aspects of computing, the concepts are independent of the technology used. Depending on the Memory model (addressing scheme)|memory model, paged memory functionality is usually hardwired into a CPU/MCU by using a Memory Management Unit (MMU) or Memory protection unit|Memory Protection Unit (MPU) and separately enabled by privileged system code in the operating system's Kernel (operating system)|kernel. In CPUs implementing the x86 instruction set architecture (ISA) for instance, the memory paging is enabled via the CR0 control register. == History == In the 1960s, swapping was an early virtual memory technique. An entire program or entire Memory segmentation|segment would be "swapped out" (or "rolled out") from RAM to disk or drum, and another one would be "swapped in" (or "rolled in"). A swapped-out program would be current but its execution would be suspended while its RAM was in use by another program; a program with a swapped-out segment could continue running until it needed that segment, at which point it would be suspended until the segment was swapped in. A program might include multiple Overlay (programming)|overlays that occupy the same memory at different times. Overlays are not a method of paging RAM to disk but merely of minimizing the program's RAM use. Subsequent architectures used memory segmentation, and individual program segments became the units exchanged between disk and RAM. A segment was the program's entire code segment or data segment, or sometimes other large data structures. These segments had to be contiguous data storage|contiguous when resident in RAM, requiring additional computation and movement to remedy Fragmentation (computer)|fragmentation. Ferranti's Atlas (computer)|Atlas, and the Atlas Supervisor developed at the University of Manchester, (1962), was the first system to implement memory paging. Subsequent early machines, and their operating systems, supporting paging include the IBM M44/44X and its MOS operating system (1964),, the SDS 940 and the Berkeley Timesharing System (1966), a modified IBM System/360 Model 40 and the IBM CP-40|CP-40 operating system (1967), the IBM System/360 Model 67 and operating systems such as TSS/360 and CP/CMS (1967), the RCA Spectra 70#Model 70/46|RCA 70/46 and the Time Sharing Operating System (1967), the GE 645 and Multics (1969), and the PDP-10 with added Raytheon BBN|BBN-designed paging hardware and the TENEX (operating system)|TENEX operating system (1969). Those machines, and subsequent machines supporting memory paging, use either a set of page address registers or in-memory page tables and some systems have cascaded page tables.}} to allow the processor to operate on arbitrary pages anywhere in RAM as a seemingly contiguous logical address space. These pages became the units exchanged between disk and RAM. ==Page faults==  When a process tries to reference a page not currently present in RAM, the processor treats this invalid memory reference as a page fault and transfers control from the program to the operating system. The operating system must: # Determine the location of the data on disk. # Obtain an empty page frame in RAM to use as a container for the data. # Load the requested data into the available page frame. # Update the page table to refer to the new page frame. # Return control to the program, transparently retrying the Instruction (computer science)|instruction that caused the page fault. When all page frames are in use, the operating system must select a page frame to reuse for the page the program now needs. If the evicted page frame was dynamic allocation|dynamically allocated by a program to hold data, or if a program modified it since it was read into RAM (in other words, if it has become "dirty"), it must be written out to disk before being freed. If a program later references the evicted page, another page fault occurs and the page must be read back into RAM. The method the operating system uses to select the page frame to reuse, which is its page replacement algorithm, is important to efficiency. The operating system predicts the page frame least likely to be needed soon, often through the Page replacement algorithm#Least recently used|least recently used (LRU) algorithm or an algorithm based on the program's working set. To further increase responsiveness, paging systems may predict which pages will be needed soon, preemptively loading them into RAM before a program references them. == Page replacement techniques ==  ; Demand paging : When pure demand paging is used, pages are loaded only when they are referenced. A program from a memory mapped file begins execution with none of its pages in RAM. As the program commits page faults, the operating system copies the needed pages from a file, e.g., memory-mapped file, paging file, or a swap partition containing the page data into RAM.  ; Anticipatory paging : This technique, sometimes also called "swap prefetch," predicts which pages will be referenced soon, to minimize future page faults. For example, after reading a page to service a page fault, the operating system may also read the next few pages even though they are not yet needed (a prediction using locality of reference). If a program ends, the operating system may delay freeing its pages, in case the user runs the same program again. ; Free page queue, stealing, and reclamation : The free page queue is a list of page frames that are available for assignment. Preventing this queue from being empty minimizes the computing necessary to service a page fault. Some operating systems periodically look for pages that have not been recently referenced and then free the page frame and add it to the free page queue, a process known as "page stealing". Some operating systems support "page reclamation"; if a program commits a page fault by referencing a page that was stolen, the operating system detects this and restores the page frame without having to read the contents back into RAM. ; Pre-cleaning : The operating system may periodically pre-clean dirty pages: write modified pages back to disk even though they might be further modified. This minimizes the amount of cleaning needed to obtain new page frames at the moment a new program starts or a new data file is opened, and improves responsiveness. (Unix operating systems periodically use sync (Unix)|sync to pre-clean all dirty pages; Windows operating systems use "modified page writer" threads.) ==Thrashing==  After completing initialization, most programs operate on a small number of code and data pages compared to the total memory the program requires.  The pages most frequently accessed are called the working set. When the working set is a small percentage of the system's total number of pages, virtual memory systems work most efficiently and an insignificant amount of computing is spent resolving page faults. As the working set grows, resolving page faults remains manageable until the growth reaches a critical point. Then faults go up dramatically and the time spent resolving them overwhelms time spent on the computing the program was written to do. This condition is referred to as Thrashing (computer science)|thrashing. Thrashing occurs on a program that works with huge data structures, as its large working set causes continual page faults that drastically slow down the system. Satisfying page faults may require freeing pages that will soon have to be re-read from disk. "Thrashing" is also used in contexts other than virtual memory systems; for example, to describe cache (computing)|cache issues in computing or silly window syndrome in networking. A worst case might occur on VAX processors. A single MOVL crossing a page boundary could have a source operand using a displacement deferred addressing mode, where the longword containing the operand address crosses a page boundary, and a destination operand using a displacement deferred addressing mode, where the longword containing the operand address crosses a page boundary, and the source and destination could both cross page boundaries. This single instruction references ten pages; if not all are in RAM, each will cause a page fault. As each fault occurs the operating system needs to go through the extensive memory management routines perhaps causing multiple I/Os which might include writing other process pages to disk and reading pages of the active process from disk.  If the operating system could not allocate ten pages to this program, then remedying the page fault would discard another page the instruction needs, and any restart of the instruction would fault again. To decrease excessive paging and resolve thrashing problems, a user can increase the number of pages available per program, either by running fewer programs concurrently or increasing the amount of RAM in the computer. ==Sharing== In multi-programming or in a multi-user environment, many users may execute the same program, written so that its code and data are in separate pages. To minimize RAM use, all users share a single copy of the program. Each process's page table is set up so that the pages that address code point to the single shared copy, while the pages that address data point to different physical pages for each process. Different programs might also use the same libraries. To save space, only one copy of the shared library is loaded into physical memory. Programs which use the same library have virtual addresses that map to the same pages (which contain the library's code and data). When programs want to modify the library's code, they use copy-on-write, so memory is only allocated when needed. Shared memory is an efficient way of communication between programs. Programs can share pages in memory, and then write and read to exchange data. ==Implementations==  The first computer to support paging was the supercomputer Atlas Computer (Manchester)|Atlas, jointly developed by Ferranti, the University of Manchester and Plessey in 1963. The machine had an associative (Content-addressable memory|content-addressable) memory with one entry for each 512 word page. The Supervisor{{cite book  |last1       = Kilburn  |first1      = T.  |last2       = Payne  |first2      = R. B.  |last3       = Howarth  |first3      = D. J.  |title       = Computers - Key to Total Systems Control  |series      = Conferen ...
