In mathematics, "coalgebras" or "cogebras" are structures that are dual (category theory)|dual (in the category theory|category-theoretic sense of reversing Category theory#Morphisms|arrows) to unital algebra|unital associative algebras. The axioms of unital associative algebras can be formulated in terms of commutative diagrams. Turning all arrows around, one obtains the axioms of coalgebras. Every coalgebra, by (vector space) Dual space|duality, gives rise to an algebra, but not in general the other way. In #Finite dimensions|finite dimensions, this duality goes in both directions (#Finite dimensions|see below). Coalgebras occur naturally in a number of contexts (for example, representation theory, universal enveloping algebras and group schemes). There are also "F-coalgebras", with important applications in computer science. == Informal discussion == One frequently recurring example of coalgebras occurs in representation theory, and in particular, in the representation theory of the rotation group. A primary task, of practical use in physics, is to obtain combinations of systems with different states of angular momentum and spin (physics)|spin. For this purpose, one uses the Clebsch–Gordan coefficients. Given two systems <math>A,B</math> with angular momenta <math>j_A</math> and <math>j_B</math>, a particularly important task is to find the total angular momentum <math>j_A + j_B</math> given the combined state <math>|A\rangle\otimes |B\rangle</math>. This is provided by the Clebsch–Gordan coefficients#Tensor product space|total angular momentum operator, which extracts the needed quantity from each side of the tensor product. It can be written as an "external" tensor product :<math>\mathbf{J} \equiv \mathbf{j} \otimes 1 + 1 \otimes \mathbf{j}</math> The word "external" appears here, in contrast to the "internal" tensor product of a tensor algebra. A tensor algebra comes with a tensor product (the internal one); it can also be equipped with a second tensor product, the "external" one, or the Tensor algebra#Coproduct|coproduct, having the form above.  That they are two different products is emphasized by recalling that the internal tensor product of a vector and a scalar is just simple scalar multiplication. The external product keeps them separated. In this setting, the coproduct is the map :<math>\Delta: J\to J\otimes J</math> that takes :<math>\Delta: \mathbf{j} \mapsto \mathbf{j} \otimes 1 + 1 \otimes \mathbf{j}</math> For this example, <math>J</math> can be taken to be one of the spin representations of the rotation group, with the fundamental representation being the common-sense choice. This coproduct can be lift (mathematics)|lifted to all of the tensor algebra, by a simple lemma that applies to free objects: the tensor algebra is a free algebra, therefore, any homomorphism defined on a subset can be extended to the entire algebra. Examining the lifting in detail, one observes that the coproduct behaves as the shuffle product, essentially because the two factors above, the left and right <math>\mathbf{j}</math> must be kept in sequential order during products of multiple angular momenta (rotations are not commutative).   The peculiar form of having the <math>\mathbf{j}</math> appear only once in the coproduct, rather than (for example) defining <math>\mathbf{j} \mapsto \mathbf{j} \otimes \mathbf{j}</math> is in order to maintain linearity: for this example, (and for representation theory in general), the coproduct "must" be linear. As a general rule, the coproduct in representation theory is reducible; the factors are given by the Littlewood–Richardson rule. (The Littlewood–Richardson rule conveys the same idea as the Clebsch–Gordan coefficients, but in a more general setting). The formal definition of the coalgebra, below, abstracts away this particular special case, and its requisite properties, into a general setting. == Formal definition == Formally, a coalgebra over a field (mathematics)|field "K" is a vector space "C" over "K" together with multilinear map|"K"-linear maps Δ: "C" → "C" ⊗ "C" and ε: "C" → "K" such that # <math>(\mathrm{id}_C \otimes \Delta) \circ \Delta = (\Delta \otimes \mathrm{id}_C) \circ \Delta</math> # <math>(\mathrm{id}_C \otimes \varepsilon) \circ \Delta = \mathrm{id}_C = (\varepsilon \otimes \mathrm{id}_C) \circ \Delta</math>. (Here ⊗ refers to the Tensor product of modules|tensor product over "K" and id is the identity function.) Equivalently, the following two diagrams commutative diagram|commute: File:Defining diagrams of coalgebra.png|center|800px In the first diagram, "C" ⊗ ("C" ⊗ "C") is identified with ("C" ⊗ "C") ⊗ "C"; the two are naturally Isomorphism|isomorphic. |page=12}} Similarly, in the second diagram the naturally isomorphic spaces "C", "C" ⊗ "K" and "K" ⊗ "C" are identified.|page=10}} The first diagram is the dual of the one expressing associativity of algebra multiplication (called the coassociativity of the comultiplication); the second diagram is the dual of the one expressing the existence of a multiplicative identity element|identity. Accordingly, the map Δ is called the "comultiplication" (or "coproduct") of "C" and ε is the "" of "C". == Examples == Take an arbitrary Set (mathematics)|set "S" and form the "K"-vector space "C" = "K"<sup>("S")</sup> with basis (linear algebra)|basis "S", as follows. The elements of this vector space "C" are those functions from "S" to "K" that map all but finitely many elements of "S" to zero; identify the element "s" of "S" with the function that maps "s" to 1 and all other elements of "S" to 0. Define  :Δ("s") = "s" ⊗ "s" and  ε("s") = 1 for all "s" in "S". By linearity, both Δ and ε can then uniquely be extended to all of "C". The vector space "C" becomes a coalgebra with comultiplication Δ and counit ε. As a second example, consider the polynomial ring "K" in one indeterminate (variable)|indeterminate "X". This becomes a coalgebra (the "divided power structure|divided power coalgebra"|page=3}}See also Raianu, Serban.  , p.&nbsp;2.) if for all "n" ≥ 0 one defines:  :<math>\Delta(X^n) = \sum_{k=0}^n \dbinom{n}{k} X^k\otimes X^{n-k},</math> :<math>\varepsilon(X^n)=\begin{cases} 1& \mbox{if } n=0\\ 0& \mbox{if } n>0 \end{cases}</math> Again, because of linearity, this suffices to define Δ and ε uniquely on all of "K". Now "K" is both a unital associative algebra and a coalgebra, and the two structures are compatible. Objects like this are called bialgebras, and in fact most of the important coalgebras considered in practice are bialgebras.  Examples of coalgebras include the tensor algebra, the exterior algebra, Hopf algebras and Lie bialgebras.  Unlike the polynomial case above, none of these are commutative. Therefore, the coproduct becomes the shuffle product, rather than the divided power structure given above. The shuffle product is appropriate, because it preserves the order of the terms appearing in the product, as is needed by non-commutative algebras. The singular homology of a topological space forms a graded coalgebra whenever the Künneth theorem|Künneth isomorphism holds, e.g. if the coefficients are taken to be a field. If "C" is the "K"-vector space with basis (linear algebra)|basis {"s", "c"}, consider Δ: "C" → "C" ⊗ "C" is given by :Δ("s") = "s" ⊗ "c" + "c" ⊗ "s" :Δ("c") = "c" ⊗ "c" − "s" ⊗ "s" and ε: "C" → "K" is given by :ε("s") = 0 :ε("c") = 1 In this situation, ("C", Δ, ε) is a coalgebra known as "trigonometric coalgebra".See also |page=4}}, and |page=55}}, Ex. 1.1.5.Raianu, Serban.  , p.&nbsp;1. For a locally finite poset "P" with set of intervals "J", define the "incidence coalgebra" "C" with "J" as basis. The comultiplication and counit are defined as :<math> \Delta = \sum_{y \in }  \otimes  \text{ for } x \leq z \ . </math> :<math>\varepsilon = \begin{cases} 1 & \text{if } x=y, \\ 0 & \text{if } x \ne y. \end{cases}</math> The intervals of length zero correspond to points of "P" and are group-like elements.Montgomery (1993) p.61 == Finite dimensions == In finite dimensions, the duality between algebras and coalgebras is closer: the dual of a finite-dimensional (unital associative) algebra is a coalgebra, while the dual of a finite-dimensional coalgebra is a (unital associative) algebra. In general, the dual of an algebra may not be a coalgebra. The key point is that in finite dimensions,  and  are isomorphic. To distinguish these: in general, algebra and coalgebra are dual "notions" (meaning that their axioms are dual: reverse the arrows), while for finite dimensions, they are also dual "objects" (meaning that a coalgebra is the dual object of an algebra and conversely). If "A" is a "finite-dimensional" unital associative "K"-algebra, then its "K"-dual "A"<sup>∗</sup> consisting of all "K"-linear maps from "A" to "K" is a coalgebra. The multiplication of "A" can be viewed as a linear map , which when dualized yields a linear map . In the finite-dimensional case,  is naturally isomorphic to , so this defines a comultiplication on "A"<sup>∗</sup>. The counit of "A"<sup>∗</sup> is given by evaluating linear functionals at 1. == Sweedler notation == When working with coalgebras, a certain notation for the comultiplication simplifies the formulas considerably and has become quite popular. Given an element "c" of the coalgebra ("C", Δ, ε), there exist elements "c" and "c" in "C" such that  :<math>\Delta(c)=\sum_i c_{(1)}^{(i)}\otimes c_{(2)}^{(i)}</math> Note that neither the number of terms in this sum, nor the exact values of each <math>c_{(1)}^{(i)}</math> or <math>c_{(2)}^{(i)}</math>, are uniquely determined by <math>c</math>; there is only a promise that there are finitely many terms, and that the full sum of all these terms <math>c_{(1)}^{(i)}\otimes c_{(2)}^{(i)}</math> have the right value <math>\Delta(c)</math>. In "Sweedler's notation",Underwood (2011) p.35 (so named after Moss Sweedler), this is abbreviated to :<math>\Delta(c)=\sum_{(c)} c_{(1)}\otimes c_{(2)}.</math> The fact that ε is a counit can then be expressed with the following formula :<math>c=\sum_{(c)} \varepsilon(c_{(1)})c_{(2)} = \sum_{(c)} c_{(1)}\varepsilon(c_{(2)}).\;</math> Here it is understood that the sums have the same number of terms, and the same lists of values for <math>c_{(1)}</math> and <math>c_{(2)}</math>, as in the previous sum for <math>\Delta(c)</math>. The coassociativity of Δ can be expressed as  :<math>\sum_{(c)}c_{(1)}\otimes\left(\sum_{(c_{(2)})}(c_{(2)})_{(1)}\otimes (c_{(2)})_{(2)}\right) = \sum_{(c)}\left( \sum_{(c_{(1)})}(c_{(1)})_{(1)}\otimes (c_{(1)})_{(2)}\right) \otimes c_{(2)}.</math> In Sweedler's notation, both of these expressions are written as :<math>\sum_{(c)} c_{(1)}\otimes c_{(2)}\otimes c_{(3)}.</math> Some authors omit the summation symbols as well; in this sumless Sweedler notation, one writes :<math>\Delta(c)=c_{(1)}\otimes c_{(2)}</math> and :<math>c=\varepsilon(c_{(1)})c_{(2)} = c_{(1)}\varepsilon(c_{(2)}).\;</math> Whenever a variable with lowered and parenthesized index is encountered in an expression of this kind, a summation symbol for that variable is implied. == Further concepts and facts == A coalgebra  is called "co-commutative" if <math>\sigma\circ\Delta = \Delta</math>, where  is the "K"-linear map defined by  for all "c", "d" in "C". In Sweedler's sumless notation, "C" is co-commutative if and only if :<math>c_{(1)}\otimes c_{(2)}=c_{(2)}\otimes c_{(1)}</math> for all "c" in "C". (It's important to understand that the implied summation is significant here: it is not required that all the summands are pairwise equal, only that the sums are equal, a much weaker requirement.) A "group-like element" (or "set-like element") is an element "x" such that  and . Contrary to what this naming convention suggests the group-like elements do not always form a group and in general they only form a set. The group-like elements of a Hopf algebra do form a group.  A "primitive element (co-algebra)|primitive element" is an element "x" that satisfies . The primitive elements of a Hopf algebra form a Lie algebra.  If {{nowrap|("C"<sub>1</sub> ...
