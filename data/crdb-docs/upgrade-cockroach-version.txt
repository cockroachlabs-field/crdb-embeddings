   Link: canonical
   Cockroach Labs
   Products
   Products CockroachDB CockroachCloud Compare Products Pricing
   Capabilities SQL Scale Resilience Geo-Partitioning Cloud Native
   Customers
   Learn
   Docs University
   Resources
   Guides Videos & Webinars Partners Forum
   Blog Get CockroachDB Contact Us
   Cockroach Labs
   Products
   Products CockroachDB CockroachCloud Compare Products Pricing
   Capabilities SQL Scale Resilience Geo-Partitioning Cloud Native
   Customers
   Learn
   Docs University
   Resources
   Guides Videos & Webinars Partners Forum
   Blog Get CockroachDB Contact Us

                          Upgrade to CockroachDB v20.2

   Contribute 
     * Edit This Page
     * Report Doc Issue
     * Suggest New Content

   Because of CockroachDB's multi-active availability design, you can perform
   a "rolling upgrade" of your CockroachDB cluster. This means that you can
   upgrade nodes one at a time without interrupting the cluster's overall
   health and operations.

Step 1. Verify that you can upgrade

   To upgrade to a new version, you must first be on a production release of
   the previous version. The release does not need to be the latest
   production release of the previous version, but it must be a production
   release rather than a testing release (alpha/beta).

   Therefore, if you are upgrading from v20.1 to v20.2, or from a testing
   release (alpha/beta) of v20.1 to v20.2:

    1. First upgrade to a production release of v20.1. Be sure to complete
       all the steps.

    2. Then return to this page and perform a second rolling upgrade to
       v20.2.

   If you are upgrading from any production release of v20.1, or from any
   earlier v20.2 release, you do not have to go through intermediate
   releases; continue to step 2.

Step 2. Prepare to upgrade

   Before starting the upgrade, complete the following steps.

  Check load balancing

   Make sure your cluster is behind a load balancer, or your clients are
   configured to talk to multiple nodes. If your application communicates
   with a single node, stopping that node to upgrade its CockroachDB binary
   will cause your application to fail.

  Check cluster health

   Verify the overall health of your cluster using the Admin UI. On the
   Cluster Overview:

     * Under Node Status, make sure all nodes that should be live are listed
       as such. If any nodes are unexpectedly listed as suspect or dead,
       identify why the nodes are offline and either restart them or
       decommission them before beginning your upgrade. If there are dead and
       non-decommissioned nodes in your cluster, it will not be possible to
       finalize the upgrade (either automatically or manually).

     * Under Replication Status, make sure there are 0 under-replicated and
       unavailable ranges. Otherwise, performing a rolling upgrade increases
       the risk that ranges will lose a majority of their replicas and cause
       cluster unavailability. Therefore, it's important to identify and
       resolve the cause of range under-replication and/or unavailability
       before beginning your upgrade.

     * In the Node List:

          * Make sure all nodes are on the same version. If any nodes are
            behind, upgrade them to the cluster's current version first, and
            then start this process over.
          * Make sure capacity and memory usage are reasonable for each node.
            Nodes must be able to tolerate some increase in case the new
            version uses more resources for your workload. Also go to Metrics
            > Dashboard: Hardware and make sure CPU percent is reasonable
            across the cluster. If there's not enough headroom on any of
            these metrics, consider adding nodes to your cluster before
            beginning your upgrade.

  Review breaking changes

   Review the backward-incompatible changes in v20.2, and if any affect your
   application, make necessary changes.

  Let ongoing bulk operations finish

   Make sure there are no bulk imports or schema changes in progress. These
   are complex operations that involve coordination across nodes and can
   increase the potential for unexpected behavior during an upgrade.

   To check for ongoing imports or schema changes, use SHOW JOBS or check the
   Jobs page in the Admin UI.

Step 3. Decide how the upgrade will be finalized

   Note:

   This step is relevant only when upgrading from v20.1.x to v20.2. For
   upgrades within the v20.2.x series, skip this step.

   By default, after all nodes are running the new version, the upgrade
   process will be auto-finalized. This will enable certain features and
   performance improvements introduced in v20.2. However, it will no longer
   be possible to perform a downgrade to v20.1. In the event of a
   catastrophic failure or corruption, the only option will be to start a new
   cluster using the old binary and then restore from one of the backups
   created prior to performing the upgrade. For this reason, we recommend
   disabling auto-finalization so you can monitor the stability and
   performance of the upgraded cluster before finalizing the upgrade, but
   note that you will need to follow all of the subsequent directions,
   including the manual finalization in step 5:

    1. Upgrade to v20.1, if you haven't already.

    2. Start the cockroach sql shell against any node in the cluster.

    3. Set the cluster.preserve_downgrade_option cluster setting:

       copy

 > SET CLUSTER SETTING cluster.preserve_downgrade_option = '20.2';

       It is only possible to set this setting to the current cluster
       version.

  Features that require upgrade finalization

   This information is TBD pending further development of CockroachDB v20.2.

Step 4. Perform the rolling upgrade

   For each node in your cluster, complete the following steps. Be sure to
   upgrade only one node at a time, and wait at least one minute after a node
   rejoins the cluster to upgrade the next node. Simultaneously upgrading
   more than one node increases the risk that ranges will lose a majority of
   their replicas and cause cluster unavailability.

   Tip:

   We recommend creating scripts to perform these steps instead of performing
   them manually. Also, if you are running CockroachDB on Kubernetes, see our
   documentation on single-cluster and/or multi-cluster orchestrated
   deployments for upgrade guidance instead.

    1. Connect to the node.

    2. Stop the cockroach process.

       Without a process manager like systemd, use this command:

       copy

 $ pkill cockroach

       If you are using systemd as the process manager, use this command to
       stop a node without systemd restarting it:

       copy

 $ systemctl stop <systemd config filename>

       Then verify that the process has stopped:

       copy

 $ ps aux | grep cockroach

       Alternately, you can check the node's logs for the message server
       drained and shutdown completed.

    3. Download and install the CockroachDB binary you want to use:

       Mac Linux

       copy

 $ curl -O https://binaries.cockroachdb.com/cockroach-v20.2.0-alpha.2.darwin-10.9-amd64.tgz

       copy

 $ tar xfz cockroach-v20.2.0-alpha.2.darwin-10.9-amd64.tgz

       copy

 $ wget https://binaries.cockroachdb.com/cockroach-v20.2.0-alpha.2.linux-amd64.tgz

       copy

 $ tar xfz cockroach-v20.2.0-alpha.2.linux-amd64.tgz

    4. If you use cockroach in your $PATH, rename the outdated cockroach
       binary, and then move the new one into its place:

       Mac Linux

       copy

 i="$(which cockroach)"; mv "$i" "$i"_old

       copy

 $ cp -i cockroach-v20.2.0-alpha.2.darwin-10.9-amd64/cockroach /usr/local/bin/cockroach

       copy

 i="$(which cockroach)"; mv "$i" "$i"_old

       copy

 $ cp -i cockroach-v20.2.0-alpha.2.linux-amd64/cockroach /usr/local/bin/cockroach

    5. Start the node to have it rejoin the cluster.

       Without a process manager like systemd, re-run the cockroach start
       command that you used to start the node initially, for example:

       copy

 $ cockroach start \
 --certs-dir=certs \
 --advertise-addr=<node address> \
 --join=<node1 address>,<node2 address>,<node3 address>

       If you are using systemd as the process manager, run this command to
       start the node:

       copy

 $ systemctl start <systemd config filename>

    6. Verify the node has rejoined the cluster through its output to stdout
       or through the Admin UI.

       Note:

       To access the Admin UI for a secure cluster, create a user with a
       password. Then open a browser and go to https://<any node's external
       IP address>:8080. On accessing the Admin UI, you will see a Login
       screen, where you will need to enter your username and password.

    7. If you use cockroach in your $PATH, you can remove the old binary:

       copy

 $ rm /usr/local/bin/cockroach_old

       If you leave versioned binaries on your servers, you do not need to do
       anything.

    8. Wait at least one minute after the node has rejoined the cluster, and
       then repeat these steps for the next node.

Step 5. Finish the upgrade

   Note:

   This step is relevant only when upgrading from v20.1.x to v20.2. For
   upgrades within the v20.2.x series, skip this step.

   If you disabled auto-finalization in step 3, monitor the stability and
   performance of your cluster for as long as you require to feel comfortable
   with the upgrade (generally at least a day) and remember to prevent new
   schema changes and changes to user privileges. If during this time you
   decide to roll back the upgrade, repeat the rolling restart procedure with
   the old binary.

   Once you are satisfied with the new version:

    1. Start the cockroach sql shell against any node in the cluster.

    2. Re-enable auto-finalization:

       copy

 > RESET CLUSTER SETTING cluster.preserve_downgrade_option;

Troubleshooting

   After the upgrade has finalized (whether manually or automatically), it is
   no longer possible to downgrade to the previous release. If you are
   experiencing problems, we therefore recommend that you:

    1. Run the cockroach debug zip command against any node in the cluster to
       capture your cluster's state.

    2. Reach out for support from Cockroach Labs, sharing your debug zip.

   In the event of catastrophic failure or corruption, the only option will
   be to start a new cluster using the old binary and then restore from one
   of the backups created prior to performing the upgrade.

See also

     * View Node Details
     * Collect Debug Information
     * View Version Details
     * Release notes for our latest version

   Was this page helpful?

   Yes No
     * Product
          * CockroachDB
          * CockroachCloud
          * Compare
          * Pricing
          * What's New
          * Get CockroachDB
          * Sign In
     * Resources
          * Guides
          * Videos & Webinars
          * Architecture Overview
          * FAQ
          * Security
     * Learn
          * Docs
          * University
     * Support Channels
          * Forum
          * Slack
          * Support Portal
          * Contact Us
     * Company
          * About
          * Blog
          * Careers
          * Customers
          * Events
          * News
          * Privacy
   © 2020 Cockroach Labs
   Thank you for downloading CockroachDB
   Keep up-to-date with CockroachDB software releases and usage best
   practices
   Keep up-to-date with CockroachDB software releases and usage best
   practices
